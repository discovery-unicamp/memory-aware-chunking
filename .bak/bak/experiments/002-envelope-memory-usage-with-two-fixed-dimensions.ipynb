{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Envelope Memory Usage with a Two Fixed Dimensions\n",
    "\n",
    "This experiment aims to evaluate the memory usage of the envelope seismic attribute operator with two fixed dimensions.\n",
    "On this notebook you will find:\n",
    "- The problem statement\n",
    "- The data collection for the experiment\n",
    "- The evaluation of the experiment results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "The envelope seismic attribute operator is a crucial process in seismic data analysis.\n",
    "It enhances seismic data by extracting the envelope of the seismic signal, which is calculated by taking the absolute value of the Hilbert transform of the seismic data.\n",
    "This operator is widely used in seismic interpretation, inversion, and attribute analysis.\n",
    "\n",
    "In this experiment, we aim to evaluate the memory usage of the envelope seismic attribute operator when applied to synthetic seismic data. To achieve this, we will:\n",
    "\n",
    "1. Generate synthetic seismic data.\n",
    "2. Apply the envelope operator to the synthetic data using the [DASF](https://github.com/discovery-unicamp/dasf-core) framework.\n",
    "3. Assess the memory usage during this process using [TraceQ](https://github.com/discovery-unicamp/traceq).\n",
    "\n",
    "Our evaluation will focus on two fixed dimensions (such as inline, crossline, or time).\n",
    "This means that we will group the results by two of these dimensions and measure the memory usage for each group, while the third dimension will vary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "\n",
    "In this section, we will outline the steps needed to collect the necessary data for our experiment. The process is organized into the following steps:\n",
    "\n",
    "1. **Setup Environment:**\n",
    "  - Set up the environment with proper env variables and global constants to use during the experiment.\n",
    "\n",
    "2. **Setup Dependencies:**\n",
    "  - Set up the virtual environment running this notebook with the required dependencies.\n",
    "\n",
    "3. **Setup the output directory:**\n",
    "  - On this step we will setup the output directory in which we will save the experiment results.\n",
    "\n",
    "4. **Generate Synthetic Seismic Data:**\n",
    "  - Generate synthetic seismic data within a specified range of dimensions.\n",
    "\n",
    "5. **Execute the Envelope Operator:**\n",
    "  - Apply the envelope operator to the synthetic data using the prepared environment and tools.\n",
    "\n",
    "After completing these steps, we will have the data generated by TraceQ to evaluate the memory usage of the envelope operator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Environment\n",
    "\n",
    "During the environment setup, we need to:\n",
    "- Proper configure `PYTHONPATH`\n",
    "- Setup dependencies\n",
    "\n",
    "Below, we're configuring the `PYTHONPATH` to allow using the tools we've coded for the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/delucca/.pyenv/versions/3.10.14/lib/python310.zip', '/home/delucca/.pyenv/versions/3.10.14/lib/python3.10', '/home/delucca/.pyenv/versions/3.10.14/lib/python3.10/lib-dynload', '', '/home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages', '/home/delucca/src/unicamp/msc/dask-auto-chunking/libs/helpers', '/home/delucca/src/unicamp/msc/dask-auto-chunking/libs/traceq']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "helpers_path = os.path.abspath('../libs/helpers')\n",
    "traceq_path = os.path.abspath('../libs/traceq')\n",
    "\n",
    "helpers_path not in sys.path and sys.path.append(helpers_path)\n",
    "traceq_path not in sys.path and sys.path.append(traceq_path)\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets setup some relevant global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment config:\n",
      "{ 'LOG_LEVEL': 'DEBUG',\n",
      "  'LOG_TRANSPORTS': ['CONSOLE', 'FILE'],\n",
      "  'NUM_SAMPLES': 200,\n",
      "  'NUM_XLINES': 200,\n",
      "  'RANGE_SIZE': 15,\n",
      "  'STEP_SIZE': 100}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "LOG_TRANSPORTS = ['CONSOLE','FILE']\n",
    "LOG_LEVEL = 'DEBUG'\n",
    "\n",
    "NUM_XLINES = 200\n",
    "NUM_SAMPLES = 200\n",
    "STEP_SIZE = 100\n",
    "RANGE_SIZE = 15\n",
    "\n",
    "print('Experiment config:')\n",
    "pprint({\n",
    "    'LOG_TRANSPORTS': LOG_TRANSPORTS,\n",
    "    'LOG_LEVEL': LOG_LEVEL,\n",
    "    'NUM_XLINES': NUM_XLINES,\n",
    "    'NUM_SAMPLES': NUM_SAMPLES,\n",
    "    'STEP_SIZE': STEP_SIZE,\n",
    "    'RANGE_SIZE': RANGE_SIZE\n",
    "}, indent=2, sort_dicts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Dependencies\n",
    "\n",
    "Before running this step, make sure you are running this notebook in the environment defined by the `.python-version` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to install the dependencies for the tools we use during the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: segyio==1.9.12 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from -r ../libs/helpers/requirements.txt (line 1)) (1.9.12)\n",
      "Requirement already satisfied: scipy==1.14.1 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from -r ../libs/helpers/requirements.txt (line 2)) (1.14.1)\n",
      "Requirement already satisfied: numpy==1.26.4 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from -r ../libs/helpers/requirements.txt (line 3)) (1.26.4)\n",
      "Requirement already satisfied: dask==2024.9.1 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from -r ../libs/helpers/requirements.txt (line 4)) (2024.9.1)\n",
      "Requirement already satisfied: msgpack==1.0.8 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from -r ../libs/helpers/requirements.txt (line 5)) (1.0.8)\n",
      "Collecting distributed==2024.9.1 (from -r ../libs/helpers/requirements.txt (line 6))\n",
      "  Downloading distributed-2024.9.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: click>=8.1 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from dask==2024.9.1->-r ../libs/helpers/requirements.txt (line 4)) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from dask==2024.9.1->-r ../libs/helpers/requirements.txt (line 4)) (3.0.0)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from dask==2024.9.1->-r ../libs/helpers/requirements.txt (line 4)) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from dask==2024.9.1->-r ../libs/helpers/requirements.txt (line 4)) (24.1)\n",
      "Requirement already satisfied: partd>=1.4.0 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from dask==2024.9.1->-r ../libs/helpers/requirements.txt (line 4)) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from dask==2024.9.1->-r ../libs/helpers/requirements.txt (line 4)) (6.0.2)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from dask==2024.9.1->-r ../libs/helpers/requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from dask==2024.9.1->-r ../libs/helpers/requirements.txt (line 4)) (8.5.0)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from distributed==2024.9.1->-r ../libs/helpers/requirements.txt (line 6)) (3.1.4)\n",
      "Requirement already satisfied: locket>=1.0.0 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from distributed==2024.9.1->-r ../libs/helpers/requirements.txt (line 6)) (1.0.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from distributed==2024.9.1->-r ../libs/helpers/requirements.txt (line 6)) (6.0.0)\n",
      "Collecting sortedcontainers>=2.0.5 (from distributed==2024.9.1->-r ../libs/helpers/requirements.txt (line 6))\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting tblib>=1.6.0 (from distributed==2024.9.1->-r ../libs/helpers/requirements.txt (line 6))\n",
      "  Using cached tblib-3.0.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from distributed==2024.9.1->-r ../libs/helpers/requirements.txt (line 6)) (6.4.1)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from distributed==2024.9.1->-r ../libs/helpers/requirements.txt (line 6)) (2.2.3)\n",
      "Collecting zict>=3.0.0 (from distributed==2024.9.1->-r ../libs/helpers/requirements.txt (line 6))\n",
      "  Using cached zict-3.0.0-py2.py3-none-any.whl.metadata (899 bytes)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from importlib-metadata>=4.13.0->dask==2024.9.1->-r ../libs/helpers/requirements.txt (line 4)) (3.20.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from jinja2>=2.10.3->distributed==2024.9.1->-r ../libs/helpers/requirements.txt (line 6)) (2.1.5)\n",
      "Downloading distributed-2024.9.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Using cached tblib-3.0.0-py3-none-any.whl (12 kB)\n",
      "Using cached zict-3.0.0-py2.py3-none-any.whl (43 kB)\n",
      "Installing collected packages: sortedcontainers, zict, tblib, distributed\n",
      "Successfully installed distributed-2024.9.1 sortedcontainers-2.4.0 tblib-3.0.0 zict-3.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: toml==0.10.2 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from -r ../libs/traceq/requirements.txt (line 1)) (0.10.2)\n",
      "Requirement already satisfied: toolz==0.12.1 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from -r ../libs/traceq/requirements.txt (line 2)) (0.12.1)\n",
      "Requirement already satisfied: loguru==0.7.2 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from -r ../libs/traceq/requirements.txt (line 3)) (0.7.2)\n",
      "Requirement already satisfied: pydantic==2.7.1 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from -r ../libs/traceq/requirements.txt (line 4)) (2.7.1)\n",
      "Requirement already satisfied: pandas==1.5.2 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from -r ../libs/traceq/requirements.txt (line 5)) (1.5.2)\n",
      "Requirement already satisfied: plotly==5.22.0 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from -r ../libs/traceq/requirements.txt (line 6)) (5.22.0)\n",
      "Requirement already satisfied: plotly-resampler==0.10.0 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from -r ../libs/traceq/requirements.txt (line 7)) (0.10.0)\n",
      "Requirement already satisfied: kaleido==0.2.1 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from -r ../libs/traceq/requirements.txt (line 8)) (0.2.1)\n",
      "Requirement already satisfied: msgpack==1.0.8 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from -r ../libs/traceq/requirements.txt (line 9)) (1.0.8)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from pydantic==2.7.1->-r ../libs/traceq/requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from pydantic==2.7.1->-r ../libs/traceq/requirements.txt (line 4)) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from pydantic==2.7.1->-r ../libs/traceq/requirements.txt (line 4)) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from pandas==1.5.2->-r ../libs/traceq/requirements.txt (line 5)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from pandas==1.5.2->-r ../libs/traceq/requirements.txt (line 5)) (2024.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from pandas==1.5.2->-r ../libs/traceq/requirements.txt (line 5)) (1.26.4)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from plotly==5.22.0->-r ../libs/traceq/requirements.txt (line 6)) (9.0.0)\n",
      "Requirement already satisfied: packaging in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from plotly==5.22.0->-r ../libs/traceq/requirements.txt (line 6)) (24.1)\n",
      "Requirement already satisfied: dash>=2.9.0 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from plotly-resampler==0.10.0->-r ../libs/traceq/requirements.txt (line 7)) (2.18.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.8.0 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from plotly-resampler==0.10.0->-r ../libs/traceq/requirements.txt (line 7)) (3.10.7)\n",
      "Requirement already satisfied: tsdownsample>=0.1.3 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from plotly-resampler==0.10.0->-r ../libs/traceq/requirements.txt (line 7)) (0.1.3)\n",
      "Requirement already satisfied: Flask<3.1,>=1.0.4 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from dash>=2.9.0->plotly-resampler==0.10.0->-r ../libs/traceq/requirements.txt (line 7)) (3.0.3)\n",
      "Requirement already satisfied: Werkzeug<3.1 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from dash>=2.9.0->plotly-resampler==0.10.0->-r ../libs/traceq/requirements.txt (line 7)) (3.0.4)\n",
      "Requirement already satisfied: dash-html-components==2.0.0 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from dash>=2.9.0->plotly-resampler==0.10.0->-r ../libs/traceq/requirements.txt (line 7)) (2.0.0)\n",
      "Requirement already satisfied: dash-core-components==2.0.0 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from dash>=2.9.0->plotly-resampler==0.10.0->-r ../libs/traceq/requirements.txt (line 7)) (2.0.0)\n",
      "Requirement already satisfied: dash-table==5.0.0 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from dash>=2.9.0->plotly-resampler==0.10.0->-r ../libs/traceq/requirements.txt (line 7)) (5.0.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from dash>=2.9.0->plotly-resampler==0.10.0->-r ../libs/traceq/requirements.txt (line 7)) (8.5.0)\n",
      "Requirement already satisfied: requests in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from dash>=2.9.0->plotly-resampler==0.10.0->-r ../libs/traceq/requirements.txt (line 7)) (2.32.3)\n",
      "Requirement already satisfied: retrying in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from dash>=2.9.0->plotly-resampler==0.10.0->-r ../libs/traceq/requirements.txt (line 7)) (1.3.4)\n",
      "Requirement already satisfied: nest-asyncio in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from dash>=2.9.0->plotly-resampler==0.10.0->-r ../libs/traceq/requirements.txt (line 7)) (1.6.0)\n",
      "Requirement already satisfied: setuptools in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from dash>=2.9.0->plotly-resampler==0.10.0->-r ../libs/traceq/requirements.txt (line 7)) (65.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas==1.5.2->-r ../libs/traceq/requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler==0.10.0->-r ../libs/traceq/requirements.txt (line 7)) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler==0.10.0->-r ../libs/traceq/requirements.txt (line 7)) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler==0.10.0->-r ../libs/traceq/requirements.txt (line 7)) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler==0.10.0->-r ../libs/traceq/requirements.txt (line 7)) (1.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from Werkzeug<3.1->dash>=2.9.0->plotly-resampler==0.10.0->-r ../libs/traceq/requirements.txt (line 7)) (2.1.5)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from importlib-metadata->dash>=2.9.0->plotly-resampler==0.10.0->-r ../libs/traceq/requirements.txt (line 7)) (3.20.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from requests->dash>=2.9.0->plotly-resampler==0.10.0->-r ../libs/traceq/requirements.txt (line 7)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from requests->dash>=2.9.0->plotly-resampler==0.10.0->-r ../libs/traceq/requirements.txt (line 7)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from requests->dash>=2.9.0->plotly-resampler==0.10.0->-r ../libs/traceq/requirements.txt (line 7)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages (from requests->dash>=2.9.0->plotly-resampler==0.10.0->-r ../libs/traceq/requirements.txt (line 7)) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../libs/helpers/requirements.txt\n",
    "%pip install -r ../libs/traceq/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./output/002-20241002003025-37edc4'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "EXPERIMENT_ID = f'002-{datetime.now().strftime(\"%Y%m%d%H%M%S\")}-{uuid.uuid4().hex[:6]}'\n",
    "OUTPUT_DIR = f'./output/{EXPERIMENT_ID}'\n",
    "\n",
    "os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 00:45:40 - generate-seismic-data - INFO - Skipping generation of synthetic data for shape (100, 200, 200) as it already exists\n",
      "2024-10-02 00:45:40 - generate-seismic-data - INFO - Skipping generation of synthetic data for shape (200, 200, 200) as it already exists\n",
      "2024-10-02 00:45:40 - generate-seismic-data - INFO - Skipping generation of synthetic data for shape (300, 200, 200) as it already exists\n",
      "2024-10-02 00:45:40 - generate-seismic-data - INFO - Skipping generation of synthetic data for shape (400, 200, 200) as it already exists\n",
      "2024-10-02 00:45:40 - generate-seismic-data - INFO - Skipping generation of synthetic data for shape (500, 200, 200) as it already exists\n",
      "2024-10-02 00:45:40 - generate-seismic-data - INFO - Skipping generation of synthetic data for shape (600, 200, 200) as it already exists\n",
      "2024-10-02 00:45:40 - generate-seismic-data - INFO - Skipping generation of synthetic data for shape (700, 200, 200) as it already exists\n",
      "2024-10-02 00:45:40 - generate-seismic-data - INFO - Skipping generation of synthetic data for shape (800, 200, 200) as it already exists\n",
      "2024-10-02 00:45:40 - generate-seismic-data - INFO - Skipping generation of synthetic data for shape (900, 200, 200) as it already exists\n",
      "2024-10-02 00:45:40 - generate-seismic-data - INFO - Skipping generation of synthetic data for shape (1000, 200, 200) as it already exists\n",
      "2024-10-02 00:45:40 - generate-seismic-data - INFO - Skipping generation of synthetic data for shape (1100, 200, 200) as it already exists\n",
      "2024-10-02 00:45:40 - generate-seismic-data - INFO - Skipping generation of synthetic data for shape (1200, 200, 200) as it already exists\n",
      "2024-10-02 00:45:40 - generate-seismic-data - INFO - Skipping generation of synthetic data for shape (1300, 200, 200) as it already exists\n",
      "2024-10-02 00:45:40 - generate-seismic-data - INFO - Skipping generation of synthetic data for shape (1400, 200, 200) as it already exists\n",
      "2024-10-02 00:45:40 - generate-seismic-data - INFO - Skipping generation of synthetic data for shape (1500, 200, 200) as it already exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./output/002-20241002003025-37edc4/data/100-200-200.segy', './output/002-20241002003025-37edc4/data/200-200-200.segy', './output/002-20241002003025-37edc4/data/300-200-200.segy', './output/002-20241002003025-37edc4/data/400-200-200.segy', './output/002-20241002003025-37edc4/data/500-200-200.segy', './output/002-20241002003025-37edc4/data/600-200-200.segy', './output/002-20241002003025-37edc4/data/700-200-200.segy', './output/002-20241002003025-37edc4/data/800-200-200.segy', './output/002-20241002003025-37edc4/data/900-200-200.segy', './output/002-20241002003025-37edc4/data/1000-200-200.segy', './output/002-20241002003025-37edc4/data/1100-200-200.segy', './output/002-20241002003025-37edc4/data/1200-200-200.segy', './output/002-20241002003025-37edc4/data/1300-200-200.segy', './output/002-20241002003025-37edc4/data/1400-200-200.segy', './output/002-20241002003025-37edc4/data/1500-200-200.segy']\n"
     ]
    }
   ],
   "source": [
    "from helpers.datasets import generate_seismic_data\n",
    "\n",
    "DATA_OUTPUT_DIR = f'{OUTPUT_DIR}/data'\n",
    "\n",
    "synthetic_data_paths = [\n",
    "    generate_seismic_data(\n",
    "        inlines=STEP_SIZE * step_num,\n",
    "        xlines=NUM_XLINES,\n",
    "        samples=NUM_SAMPLES,\n",
    "        output_dir=DATA_OUTPUT_DIR,\n",
    "    ) for step_num in range(1, RANGE_SIZE + 1)\n",
    "] \n",
    "\n",
    "print(synthetic_data_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the envelope attribute\n",
    "\n",
    "On this step, we will execute the attribute for each generated synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 00:46:33 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "2024-10-02 00:46:33 - distributed.scheduler - INFO - State start\n",
      "2024-10-02 00:46:33 - distributed.scheduler - INFO -   Scheduler at:     tcp://127.0.0.1:45933\n",
      "2024-10-02 00:46:33 - distributed.scheduler - INFO -   dashboard at:  http://127.0.0.1:8787/status\n",
      "2024-10-02 00:46:33 - distributed.scheduler - INFO - Registering Worker plugin shuffle\n",
      "2024-10-02 00:46:33 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43375'\n",
      "2024-10-02 00:46:33 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43287', name: 0, status: init, memory: 0, processing: 0>\n",
      "2024-10-02 00:46:33 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43287\n",
      "2024-10-02 00:46:33 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46606\n",
      "2024-10-02 00:46:33 - distributed.scheduler - INFO - Receive client connection: Client-ea7f7f5c-8070-11ef-a1c0-00155df3af8b\n",
      "2024-10-02 00:46:33 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-02 00:46:33.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtraceq.profiler.main\u001b[0m:\u001b[36mrun_profiler\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mStarting profiler\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.801\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtraceq.profiler.builders\u001b[0m:\u001b[36mbuild_trace_hooks\u001b[0m:\u001b[36m20\u001b[0m - \u001b[34m\u001b[1mBuilding trace hooks for enabled metrics: [<Metric.MEMORY_USAGE: 'MEMORY_USAGE'>, <Metric.TIME: 'TIME'>]\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtraceq.profiler.metrics.memory_usage.builders\u001b[0m:\u001b[36mbuild_trace_hooks\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mEnabled memory usage backends: \"[<MemoryUsageBackend.KERNEL: 'KERNEL'>]\"\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.803\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtraceq.profiler.metrics.memory_usage.builders\u001b[0m:\u001b[36mbuild_trace_hooks\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mLoading backend: \"kernel\"\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.803\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtraceq.profiler.metrics.memory_usage.builders\u001b[0m:\u001b[36mbuild_trace_hooks\u001b[0m:\u001b[36m31\u001b[0m - \u001b[34m\u001b[1mLoaded backend: \"<module 'traceq.profiler.metrics.memory_usage.backends.kernel' from '/home/delucca/src/unicamp/msc/dask-auto-chunking/libs/traceq/traceq/profiler/metrics/memory_usage/backends/kernel.py'>\"\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.805\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtraceq.profiler.metrics.memory_usage.builders\u001b[0m:\u001b[36mbuild_trace_hooks\u001b[0m:\u001b[36m34\u001b[0m - \u001b[34m\u001b[1mChecking if backend has \"before\" function\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.805\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtraceq.profiler.metrics.memory_usage.builders\u001b[0m:\u001b[36mbuild_trace_hooks\u001b[0m:\u001b[36m43\u001b[0m - \u001b[34m\u001b[1mAdded \"before\" from \"kernel\" to hooks\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.806\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtraceq.profiler.metrics.memory_usage.builders\u001b[0m:\u001b[36mbuild_trace_hooks\u001b[0m:\u001b[36m34\u001b[0m - \u001b[34m\u001b[1mChecking if backend has \"on_sample\" function\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.807\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtraceq.profiler.metrics.memory_usage.builders\u001b[0m:\u001b[36mbuild_trace_hooks\u001b[0m:\u001b[36m43\u001b[0m - \u001b[34m\u001b[1mAdded \"on_sample\" from \"kernel\" to hooks\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.807\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtraceq.profiler.metrics.memory_usage.builders\u001b[0m:\u001b[36mbuild_trace_hooks\u001b[0m:\u001b[36m34\u001b[0m - \u001b[34m\u001b[1mChecking if backend has \"after\" function\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.808\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mtraceq.profiler.metrics.memory_usage.builders\u001b[0m:\u001b[36mbuild_trace_hooks\u001b[0m:\u001b[36m37\u001b[0m - \u001b[33m\u001b[1mBackend \"kernel\" does not have \"after\" function\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.820\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtraceq.profiler.tracer\u001b[0m:\u001b[36mexecutor_hooks\u001b[0m:\u001b[36m65\u001b[0m - \u001b[34m\u001b[1mUsing executor hooks: {'before': [<function before at 0x7fc96bfb3760>], 'on_sample': [<function capture_trace at 0x7fc96bfb2dd0>, <function capture_trace at 0x7fc9cecba830>], 'after': []}\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.823\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtraceq.profiler.main\u001b[0m:\u001b[36mrun_profiler\u001b[0m:\u001b[36m39\u001b[0m - \u001b[34m\u001b[1mUsing config: output_dir=PosixPath('output/002-20241002003025-37edc4/profile-100-200-200') logger=LoggerConfig(enabled_transports=[<Transport.CONSOLE: 'CONSOLE'>, <Transport.FILE: 'FILE'>], level=<Level.DEBUG: 'DEBUG'>) profiler=ProfilerConfig(session_id='100-200-200', enabled_metrics=[<Metric.MEMORY_USAGE: 'MEMORY_USAGE'>, <Metric.TIME: 'TIME'>], memory_usage=MemoryUsageConfig(enabled_backends=[<MemoryUsageBackend.KERNEL: 'KERNEL'>]), filepath=PosixPath('/home/delucca/src/unicamp/msc/dask-auto-chunking/libs/helpers/helpers/dask_operators.py'), entrypoint='envelope_from_segy', signature=[FunctionParameter(name='segy_path', type='str', position=0, default='None')], args=('./output/002-20241002003025-37edc4/data/100-200-200.segy',), kwargs={}, depth=3, precision=0.01, sign_traces=False, strategy='process')\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.824\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtraceq.profiler.main\u001b[0m:\u001b[36mrun_profiler\u001b[0m:\u001b[36m40\u001b[0m - \u001b[34m\u001b[1mEnabled trace hooks: dict_keys(['before', 'on_sample', 'after'])\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.824\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtraceq.profiler.main\u001b[0m:\u001b[36mrun_profiler\u001b[0m:\u001b[36m41\u001b[0m - \u001b[34m\u001b[1mEnabled metrics: [<Metric.MEMORY_USAGE: 'MEMORY_USAGE'>, <Metric.TIME: 'TIME'>]\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.825\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtraceq.profiler.main\u001b[0m:\u001b[36mrun_profiler\u001b[0m:\u001b[36m42\u001b[0m - \u001b[34m\u001b[1mUsing args: ('./output/002-20241002003025-37edc4/data/100-200-200.segy',)\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.826\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtraceq.profiler.main\u001b[0m:\u001b[36mrun_profiler\u001b[0m:\u001b[36m43\u001b[0m - \u001b[34m\u001b[1mUsing kwargs: {}\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.827\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtraceq.profiler.main\u001b[0m:\u001b[36mrun_profiler\u001b[0m:\u001b[36m44\u001b[0m - \u001b[34m\u001b[1mUsing entrypoint: envelope_from_segy\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtraceq.profiler.main\u001b[0m:\u001b[36mrun_profiler\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mStarting profiler execution for \"/home/delucca/src/unicamp/msc/dask-auto-chunking/libs/helpers/helpers/dask_operators.py\"\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtraceq.profiler.handlers\u001b[0m:\u001b[36mexecute_file\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mStarting new profiler session for file \"/home/delucca/src/unicamp/msc/dask-auto-chunking/libs/helpers/helpers/dask_operators.py\" with entrypoint set to: \"envelope_from_segy\"\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.838\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtraceq.profiler.handlers\u001b[0m:\u001b[36mexecute_file\u001b[0m:\u001b[36m22\u001b[0m - \u001b[34m\u001b[1mUsing args: ('./output/002-20241002003025-37edc4/data/100-200-200.segy',)\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.838\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtraceq.profiler.handlers\u001b[0m:\u001b[36mexecute_file\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mUsing kwargs: {}\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtraceq.profiler.handlers\u001b[0m:\u001b[36mexecute_file\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mExecuting file: /home/delucca/src/unicamp/msc/dask-auto-chunking/libs/helpers/helpers/dask_operators.py\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.840\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtraceq.profiler.handlers\u001b[0m:\u001b[36mexecute_file\u001b[0m:\u001b[36m40\u001b[0m - \u001b[34m\u001b[1mUsing function \"envelope_from_segy\" as entrypoint\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtraceq.profiler.handlers\u001b[0m:\u001b[36mexecute_file\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mCompiling code\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtraceq.profiler.handlers\u001b[0m:\u001b[36mexecute_file\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mRunning execution before hook\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.843\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtraceq.profiler.tracer\u001b[0m:\u001b[36mbefore_executor\u001b[0m:\u001b[36m83\u001b[0m - \u001b[34m\u001b[1mRunning before executor hooks\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtraceq.profiler.tracer\u001b[0m:\u001b[36mstart_sampler\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mStarting profile sampler\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtraceq.profiler.tracer\u001b[0m:\u001b[36mstart_sampler\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mUsing precision of 0.01s and process strategy\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtraceq.profiler.handlers\u001b[0m:\u001b[36mexecute_file\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mExecuting code file\u001b[0m\n",
      "\u001b[32m2024-10-02 00:46:33.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtraceq.profiler.handlers\u001b[0m:\u001b[36mexecute_file\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mRunning function: envelope_from_segy\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 15.26 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "for synthetic_data_path in synthetic_data_paths:\n",
    "    # Cleanup\n",
    "    for var_name in ['traceq', 'envelope_from_segy', 'dask', 'client', 'Client']:\n",
    "        if var_name in locals():\n",
    "            del locals()[var_name]\n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "    # Restart variables\n",
    "    import dask\n",
    "    from dask.distributed import Client\n",
    "    import traceq\n",
    "    from helpers.dask_operators import envelope_from_segy\n",
    "\n",
    "    dask.config.set({\"distributed.diagnostics.nvml\": False})\n",
    "    client = Client(n_workers=1, threads_per_worker=1)\n",
    "    \n",
    "    # Execute\n",
    "    shape = synthetic_data_path.split('/')[-1].split('.')[0]\n",
    "    traceq.load_config(\n",
    "        {\n",
    "            \"output_dir\": f'{OUTPUT_DIR}/profile-{shape}',\n",
    "            \"logger\": {\n",
    "                \"enabled_transports\": LOG_TRANSPORTS,\n",
    "                \"level\": LOG_LEVEL,\n",
    "            },\n",
    "            \"profiler\": {\n",
    "                \"session_id\": shape,\n",
    "                \"memory_usage\": {\n",
    "                    \"enabled_backends\": ['kernel'],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    r = traceq.profile(envelope_from_segy, synthetic_data_path)\n",
    "    print(r)\n",
    "    client.close()\n",
    "    ddd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('100-200-200', './output/002-20241002003025-37edc4/profile-100-200-200/100-200-200.prof'), ('1400-200-200', './output/002-20241002003025-37edc4/profile-1400-200-200/1400-200-200.prof'), ('1000-200-200', './output/002-20241002003025-37edc4/profile-1000-200-200/1000-200-200.prof'), ('1500-200-200', './output/002-20241002003025-37edc4/profile-1500-200-200/1500-200-200.prof'), ('800-200-200', './output/002-20241002003025-37edc4/profile-800-200-200/800-200-200.prof'), ('400-200-200', './output/002-20241002003025-37edc4/profile-400-200-200/400-200-200.prof'), ('1100-200-200', './output/002-20241002003025-37edc4/profile-1100-200-200/1100-200-200.prof'), ('1200-200-200', './output/002-20241002003025-37edc4/profile-1200-200-200/1200-200-200.prof'), ('300-200-200', './output/002-20241002003025-37edc4/profile-300-200-200/300-200-200.prof'), ('1300-200-200', './output/002-20241002003025-37edc4/profile-1300-200-200/1300-200-200.prof'), ('700-200-200', './output/002-20241002003025-37edc4/profile-700-200-200/700-200-200.prof'), ('500-200-200', './output/002-20241002003025-37edc4/profile-500-200-200/500-200-200.prof'), ('200-200-200', './output/002-20241002003025-37edc4/profile-200-200-200/200-200-200.prof'), ('600-200-200', './output/002-20241002003025-37edc4/profile-600-200-200/600-200-200.prof'), ('900-200-200', './output/002-20241002003025-37edc4/profile-900-200-200/900-200-200.prof')]\n"
     ]
    }
   ],
   "source": [
    "from helpers.result_handlers import load_profile_results\n",
    "zipped_sessions = list(load_profile_results(OUTPUT_DIR))\n",
    "\n",
    "print(zipped_sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the metadata normalized, and the organized data, we need now to get the peaks for each profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'kernel_memory_usage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelpers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresult_handlers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_peak, get_unit\n\u001b[0;32m----> 3\u001b[0m peaks \u001b[38;5;241m=\u001b[39m [(shape, get_peak(profile_path), get_unit(profile_path)) \u001b[38;5;28;01mfor\u001b[39;00m shape, profile_path \u001b[38;5;129;01min\u001b[39;00m zipped_sessions]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(peaks)\n",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelpers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresult_handlers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_peak, get_unit\n\u001b[0;32m----> 3\u001b[0m peaks \u001b[38;5;241m=\u001b[39m [(shape, get_peak(profile_path), \u001b[43mget_unit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile_path\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m shape, profile_path \u001b[38;5;129;01min\u001b[39;00m zipped_sessions]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(peaks)\n",
      "File \u001b[0;32m~/src/unicamp/msc/dask-auto-chunking/libs/helpers/helpers/result_handlers.py:31\u001b[0m, in \u001b[0;36mget_unit\u001b[0;34m(profile_path, metric)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_unit\u001b[39m(profile_path: \u001b[38;5;28mstr\u001b[39m, metric: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m DEFAULT_MEM_USAGE_METRIC):\n\u001b[1;32m     30\u001b[0m     profile \u001b[38;5;241m=\u001b[39m load_profile(profile_path)\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprofile\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'kernel_memory_usage'"
     ]
    }
   ],
   "source": [
    "from helpers.result_handlers import get_peak, get_unit\n",
    "\n",
    "peaks = [(shape, get_peak(profile_path), get_unit(profile_path)) for shape, profile_path in zipped_sessions]\n",
    "print(peaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can create the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "data_sorted = sorted(peaks, key=lambda x: int(x[0]))\n",
    "x_values = [int(item[0]) for item in data_sorted]\n",
    "y_values_gb = [item[1] / 1048576 for item in data_sorted]  # Memory usage in GB\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x_values, y=y_values_gb, mode='lines+markers', name='Memory Usage'))\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Inlines\",\n",
    "    yaxis_title=\"Memory Usage (GB)\",\n",
    "    xaxis=dict(showgrid=True, zeroline=True),\n",
    "    yaxis=dict(showgrid=True, zeroline=True, exponentformat=\"E\"),\n",
    "    font=dict(family=\"Courier New, monospace\", size=18, color=\"Black\"),\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "fig.write_image(f'{OUTPUT_DIR}/memory-usage-over-inlines.pdf', format=\"pdf\", engine=\"kaleido\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
