{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9e586d6-a34f-48ed-bd69-90551d30a703",
   "metadata": {},
   "source": [
    "# Chunk Size vs. Execution Time\n",
    "\n",
    "## Introduction\n",
    "This experiment focuses on exploring the relationship between chunk size and the execution time of distributed computations in Dask.\n",
    "In distributed systems like Dask, breaking large datasets into smaller chunks allows parallel computation across multiple workers.\n",
    "However, determining the optimal chunk size can be a challenging task, as it directly affects both performance and resource utilization.\n",
    "\n",
    "The goal of this experiment is to identify the chunk size that optimally balances task scheduling overhead and computation time to maximize performance.\n",
    "By testing various chunk sizes, we aim to uncover patterns and insights that can guide best practices in chunking strategies for distributed computing.\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Choosing the correct chunk size in distributed systems is crucial.\n",
    "Too small a chunk size can result in excessive overhead from task scheduling and network communication, while too large a chunk size may overwhelm individual workers’ memory and processing capabilities.\n",
    "This experiment seeks to determine the chunk size that provides the best performance by minimizing execution time while efficiently utilizing computational resources.\n",
    "\n",
    "The main challenge lies in finding the balance between task scheduling overhead and the computation time of each chunk.\n",
    "As datasets grow larger, this balance becomes increasingly important in optimizing distributed systems like Dask.\n",
    "\n",
    "## Key Questions\n",
    "\n",
    "**1. How does varying the chunk size influence execution time?**\n",
    "In distributed computations, the chunk size determines how many tasks are created and how much data each worker processes at once.\n",
    "A larger chunk size reduces the number of tasks but increases the workload per task. Conversely, smaller chunks create more tasks but reduce the per-task workload.\n",
    "We will explore how changing the chunk size impacts overall execution time, looking for patterns in how the system reacts to different configurations.\n",
    "\n",
    "**2. What is the relationship between chunk size, task scheduling overhead, and overall computation time?**\n",
    "Chunking affects not only computation time but also task scheduling.\n",
    "Task scheduling overhead refers to the time spent assigning tasks to workers, which grows with the number of tasks (i.e., smaller chunk sizes).\n",
    "The experiment will investigate this relationship, quantifying how much time is spent on task scheduling versus actual computation. Understanding this relationship is critical in finding the right balance between chunk size and system performance.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "To explore these questions, this experiment will use the following steps:\n",
    "\n",
    "1. **Dataset Selection**:\n",
    "A large seismic dataset will be synthetically generated as the test subject. The dataset will be large enough to stress the system and highlight the performance impact of different chunk sizes.\n",
    "\n",
    "2. **Algorithm Selection**:\n",
    "The experiment will utilize a tensorial algorithm commonly used in seismic data processing.\n",
    "The choice of algorithm is important because different algorithms may have varying sensitivities to chunk size and memory usage, which could affect the execution time and resource utilization.\n",
    "By focusing on specific algorithms, we will be able to measure chunking performance in a real-world scenario.\n",
    "\n",
    "4. **Varying Chunk Sizes**:\n",
    "We will manually set different chunk sizes and observe their impact on execution time. This will include both very small and very large chunk sizes to capture the full spectrum of performance behavior.\n",
    "\n",
    "5. **Task Scheduling Overhead Analysis**:\n",
    "For each chunk size, we will measure the task scheduling overhead separately from the computation time. This will help quantify the relationship between task scheduling and execution time.\n",
    "\n",
    "6. **Performance Tracking**:\n",
    "Execution time will be tracked and logged for each experiment. In addition, memory usage and CPU utilization will be monitored to ensure that resource constraints (e.g., memory saturation) do not bias the results.\n",
    "\n",
    "7. **Results Comparison**:\n",
    "Once the experiments are complete, we will analyze the results to find the optimal chunk size that balances execution time and resource utilization. A comparison will be made across different chunk sizes to identify patterns and trade-offs.\n",
    "\n",
    "This methodology will provide insights into how chunk sizes affect performance and help identify strategies to optimize chunking for future distributed computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8cf9fc-509d-4f41-b6f9-5e9e78b5454f",
   "metadata": {},
   "source": [
    "## Experiment Execution\n",
    "\n",
    "Before starting the experiment, we need to set up the environment to ensure all steps run smoothly. It is assumed that you have already installed all the required dependencies from the root requirements.txt file located at `../requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a59f2e9-38b3-48ac-88da-e4b73c420954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are libs properly linked to your sys.path? -> Yes\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def link_libs_to_path():\n",
    "    libs_path = os.path.abspath('../libs')\n",
    "    if libs_path not in sys.path:\n",
    "        sys.path.append(libs_path)\n",
    "\n",
    "    are_libs_in_sys_path = libs_path in sys.path\n",
    "    print(f\"Are libs properly linked to your sys.path? -> {'Yes' if are_libs_in_sys_path else 'No'}\")\n",
    "\n",
    "\n",
    "link_libs_to_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e6e2a3-f530-4c0a-998d-b02323fbb300",
   "metadata": {},
   "source": [
    "### Dataset Selection\n",
    "\n",
    "In this experiment, we will generate a synthetic seismic cube to serve as our dataset.\n",
    "Seismic cubes are typically large, multi-dimensional arrays, making them ideal for testing distributed computation and chunking strategies.\n",
    "\n",
    "To generate the dataset, we will utilize utility libraries that have already been linked to your sys.path during the environment setup.\n",
    "These libraries provide convenient functions for creating large datasets with configurable shapes, allowing you to adjust the size of the cube according to your machine’s available memory.\n",
    "\n",
    "You can modify the cube’s shape in the initial parameters of the notebook.\n",
    "We recommend setting the dimensions of the seismic cube based on the memory capacity of your machine to prevent memory overload and ensure smooth execution of the experiment.\n",
    "If you are unsure, start with smaller sizes and gradually increase them to explore the impact on execution time and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "905eca64-bca7-4c07-9159-dd4a1301af3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 20:32:03 - dataset-selection - INFO - Generating seismic data with dimensions: NUM_INLINES=300, NUM_XLINES=300, NUM_SAMPLES=300\n",
      "2024-10-23 20:32:03 - dataset-selection - INFO - Output will be saved to ./outputs/001-20241023203203\n",
      "2024-10-23 20:32:03 - generate-seismic-data - INFO - Generating synthetic data for shape (300, 300, 300)\n",
      "2024-10-23 20:32:08 - dataset-selection - INFO - Seismic data generation completed. Data saved to ./outputs/001-20241023203203/data/300-300-300.segy\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from utils import generate_output_dir_path\n",
    "from datasets import generate_seismic_data, load_segy, render_random_inline\n",
    "from loggers import get_named_logger\n",
    "\n",
    "logger = get_named_logger('dataset-selection')\n",
    "\n",
    "NUM_INLINES = 300\n",
    "NUM_XLINES = 300\n",
    "NUM_SAMPLES = 300\n",
    "\n",
    "OUTPUT_DIR = generate_output_dir_path('001')\n",
    "DATA_DIR = os.path.join(OUTPUT_DIR, 'experiment')\n",
    "\n",
    "logger.info(\n",
    "    f\"Generating seismic experiment with dimensions: \"\n",
    "    f\"NUM_INLINES={NUM_INLINES}, NUM_XLINES={NUM_XLINES}, NUM_SAMPLES={NUM_SAMPLES}\")\n",
    "logger.info(f\"Output will be saved to {OUTPUT_DIR}\")\n",
    "\n",
    "seismic_data_path = generate_seismic_data(\n",
    "    NUM_INLINES,\n",
    "    NUM_XLINES,\n",
    "    NUM_SAMPLES,\n",
    "    output_dir=DATA_DIR,\n",
    ")\n",
    "\n",
    "logger.info(f\"Seismic experiment generation completed. Data saved to {seismic_data_path}\")\n",
    "\n",
    "seismic_data = load_segy(seismic_data_path)\n",
    "render_random_inline(seismic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa669557-1b4d-4207-a7f1-08fd5d717562",
   "metadata": {},
   "source": [
    "### Algorithm Selection\n",
    "\n",
    "In this experiment, we will test the impact of chunk sizes on the execution of several algorithms, focusing on both seismic-specific and general-purpose computations.\n",
    "These algorithms will help us understand how chunk size affects different types of computational workloads, from simpler to more complex tasks.\n",
    "The selected algorithms include:\n",
    "\n",
    "- **Envelope**:\n",
    "The envelope algorithm is widely used in seismic processing to extract the instantaneous amplitude of a seismic signal.\n",
    "It is computationally lightweight and generally does not require significant memory resources.\n",
    "This makes it an ideal candidate for testing chunk size behavior under less memory-intensive conditions, allowing us to observe how Dask’s chunking strategies perform with lower memory consumption.\n",
    "\n",
    "- **GST3D (Generalized S-transform in 3D)**:\n",
    "GST3D is a time-frequency analysis algorithm applied to 3D seismic data.\n",
    "Unlike the envelope algorithm, GST3D is computationally heavy and memory-intensive.\n",
    "It requires multiple transformations and matrix operations across the entire seismic cube, which quickly consumes memory, especially as the data size grows.\n",
    "This algorithm will help us stress-test chunking performance under memory-constrained conditions, providing valuable insights into how Dask handles chunking for complex seismic computations.\n",
    "\n",
    "- **3D Gaussian Filtering**:\n",
    "To include a non-seismic algorithm that can still process 3D data like a seismic cube, we suggest 3D Gaussian Filtering.\n",
    "This is a standard algorithm used in image and signal processing for smoothing data and reducing noise.\n",
    "The algorithm performs convolution over the 3D array (the seismic cube), making it computationally relevant to chunking strategies in a distributed setting.\n",
    "It is not as memory-intensive as GST3D but still requires substantial computation, making it an excellent candidate for exploring how chunk size impacts non-seismic algorithms.\n",
    "\n",
    "By testing these three algorithms: one lightweight (Envelope), one heavy (GST3D), and one general-purpose (3D Gaussian Filtering), we can evaluate how chunk size affects performance in both simple and complex computational contexts.\n",
    "The goal is to find chunking strategies that strike the best balance between execution time and memory usage, based on the complexity of the algorithm and the data size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ba07358-fc46-46b6-b262-ccf079292edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 20:32:08 - algorithm-selection - INFO - Envelope using <function envelope_from_segy at 0x7fe38503e8c0>\n",
      "2024-10-23 20:32:08 - algorithm-selection - INFO - GST3D using <function gradient_structure_tensor_from_segy at 0x7fe384e38550>\n",
      "2024-10-23 20:32:08 - algorithm-selection - INFO - 3D Gaussian Filter using <function gaussian_filter_from_segy at 0x7fe384e38430>\n"
     ]
    }
   ],
   "source": [
    "from operators import envelope_from_segy, gradient_structure_tensor_from_segy, gaussian_filter_from_segy\n",
    "from loggers import get_named_logger\n",
    "\n",
    "logger = get_named_logger('algorithm-selection')\n",
    "\n",
    "apply_envelope = envelope_from_segy\n",
    "apply_gst3d = gradient_structure_tensor_from_segy\n",
    "apply_gaussian_filter = gaussian_filter_from_segy\n",
    "\n",
    "logger.info(f'Envelope using {apply_envelope}')\n",
    "logger.info(f'GST3D using {apply_gst3d}')\n",
    "logger.info(f'3D Gaussian Filter using {apply_gaussian_filter}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259d3e93-a65a-4589-8f9e-f418c11e059b",
   "metadata": {},
   "source": [
    "### Collecting Data\n",
    "\n",
    "Now that the seismic data has been generated and the algorithms have been selected, the next step involves preparing the data for the experiment.\n",
    "Here’s how we’ll proceed with collecting and organizing the necessary data for analysis:\n",
    "\n",
    "1. **Chunk Size Configuration**:\n",
    "We will begin by manually configuring different chunk sizes.\n",
    "These chunk sizes will range from very small to large, allowing us to observe the full impact on execution time and resource usage.\n",
    "Each chunk size will be applied to the same synthetic seismic dataset to ensure consistent comparison.\n",
    "\n",
    "2. **Running the Algorithms**:\n",
    "For each configured chunk size, the selected algorithms (Envelope, GST3D, and 3D Gaussian Filtering) will be applied to the seismic dataset.\n",
    "Each algorithm will be executed across multiple chunk size configurations, and the performance metrics will be recorded.\n",
    "\n",
    "3. **Task Scheduling and Execution Time Data**:\n",
    "During the execution of each algorithm, we will collect detailed performance data:\n",
    "    - Execution Time: The total time taken to process the seismic data for each algorithm using the specified chunk size. This includes both computation time and task scheduling time.\n",
    "    - Task Scheduling Overhead: Dask’s task scheduling overhead will be monitored separately to understand the impact of chunk size on the overhead. This data will help isolate the time spent on scheduling tasks versus the time spent on computation.\n",
    "    - Memory Usage and CPU Utilization: Memory consumption and CPU usage will be tracked for each run. These metrics are critical to understanding how chunk size affects system resource allocation and will help identify any memory or CPU bottlenecks.\n",
    "\n",
    "4. **Logging and Storing the Results**:\n",
    "The collected data will be logged for each chunk size configuration.\n",
    "This will include the execution time, task scheduling overhead, memory usage, and CPU utilization for all algorithms. The results will be stored in a structured format for later analysis.\n",
    "\n",
    "By collecting this data across a range of chunk sizes, we will be able to visualize the relationship between chunk size, task scheduling overhead, and execution time.\n",
    "This will allow us to identify the optimal chunk size that balances performance and resource usage, ultimately guiding best practices in distributed chunking strategies for future computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eef4098-54a0-4d15-9ac9-9b30e5363fd1",
   "metadata": {},
   "source": [
    "#### Experiment Metrics\n",
    "\n",
    "To comprehensively evaluate the performance of various chunking strategies in distributed Dask computations, we will track the following key metrics, denoted by variables:\n",
    "\n",
    "1. **Number of Chunks ($c$)**:\n",
    "The number of chunks refers to the total number of data chunks into which the dataset is divided for parallel processing.\n",
    "It represents how the dataset is split to allow distribution across multiple workers in a distributed system like Dask.\n",
    "It is expressed as: $c = \\frac{\\text{total\\_dataset\\_size}}{\\text{chunk\\_size}}$\n",
    "\n",
    "    - Lower values of $c$ (i.e., fewer chunks) mean that fewer, larger chunks are processed by workers, leading to more intensive workloads per chunk and potentially less parallelism.\n",
    "    - Higher values of $c$ (i.e., more chunks) indicate finer granularity of the workload, allowing more tasks to be distributed across workers. However, this can lead to increased task scheduling overhead, as the system needs to manage more tasks.\n",
    "\n",
    "2. **Chunk-to-Worker Ratio ($r$)**:\n",
    "This metric defines the relationship between the number of chunks ($c$) and the number of workers ($w$) available in the system.\n",
    "It is expressed as: $r = \\frac{c}{w}$\n",
    "\n",
    "    - A ratio of $r = 1$ indicates a balanced system where each worker handles exactly one chunk.\n",
    "    - If $r < 1$, there are fewer chunks than workers, potentially leading to underutilization of resources.\n",
    "    - If $r > 1$, more chunks than workers are created, resulting in multiple tasks per worker and potentially increasing scheduling overhead.\n",
    "\n",
    "3. **Relative Chunk Size ($s$)**:\n",
    "The relative chunk size measures how large each chunk is in relation to the total volume of the dataset, reflecting the proportion of the dataset handled by each chunk.\n",
    "It is expressed as: $s = \\frac{\\text{chunk\\_volume}}{\\text{dataset\\_volume}}$.\n",
    "Where the volume of a chunk can be represented as the product of the dimensions of the chunk (e.g., $v_{\\text{chunk}} = n_{\\text{inline}} \\times n_{\\text{xline}} \\times n_{\\text{samples}}$).\n",
    "\n",
    "    - Smaller values of $s$ indicate that each chunk represents a smaller fraction of the dataset’s total volume, promoting higher levels of parallelism but potentially increasing task scheduling overhead.\n",
    "    - Larger values of $s$ suggest that each chunk encompasses a significant portion of the dataset’s volume, resulting in fewer tasks that are heavier and may consume more memory and resources per worker.\n",
    "\n",
    "4. **Execution Time ($T$)**:\n",
    "This is the total time taken to complete the computation, including both task scheduling and actual processing time.\n",
    "It is the primary performance metric to assess how efficiently Dask handles different chunking configurations. Minimizing $T$ is the goal, as shorter execution times indicate better performance.\n",
    "\n",
    "5. **Task Scheduling Overhead ($O_{\\text{sched}}$)**:\n",
    "The time Dask spends scheduling tasks across workers.\n",
    "This overhead becomes significant when using many small chunks, as each chunk incurs scheduling costs.\n",
    "It is defined as the portion of the total execution time spent on task management rather than computation.\n",
    "\n",
    "6. **Memory Usage ($M_{\\text{peak}}$)**:\n",
    "This metric tracks the peak memory usage across workers during the computation.\n",
    "It is critical to monitor memory usage because larger chunks can lead to excessive memory consumption, causing performance degradation or worker crashes if memory limits are exceeded.\n",
    "Memory usage will be influenced by chunk size, and monitoring it ensures that the chunking strategy is optimized for both time and resource constraints.\n",
    "\n",
    "These metrics ($r$, $s$, $T$, $O_{\\text{sched}}$, and $M_{\\text{peak}}$) will provide a clear and comprehensive understanding of how different chunking configurations affect the performance and resource utilization of distributed computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ea06ea-08db-4d9d-afa5-d4bf42072803",
   "metadata": {},
   "source": [
    "#### Experiment Setup\n",
    "\n",
    "In this experiment, we will test the impact of varying the number of chunks relative to the number of workers available in a distributed Dask environment.\n",
    "The goal is to explore how the relationship between chunk size and the number of workers affects overall performance and resource utilization.\n",
    "\n",
    "We will investigate several key scenarios:\n",
    "\n",
    "1. **Single Chunk (Monolithic Chunking, $c = 1$)**:\n",
    "In this scenario, the entire dataset will be processed as a single chunk.\n",
    "This disables parallelism since only one worker can process the task. The chunk-to-worker ratio ($r$) is $1$ if there is one worker, and the relative chunk size ($s$) will be $1$.\n",
    "This test helps assess memory usage ($m_{\\text{usage}}$) and system behavior under minimal parallelism.\n",
    "\n",
    "2. **Few Chunks (Minimal Chunking, $c \\approx 1$)**:\n",
    "This scenario tests configurations where the number of chunks is slightly greater than $1$ but still far fewer than the available workers.\n",
    "The chunk-to-worker ratio ($r$) will still be close to $1$, and the relative chunk size ($s$) will be large, meaning each chunk represents a significant portion of the dataset.\n",
    "This helps explore how Dask handles moderate parallelism and the impact on execution time ($t_{\\text{exec}}$) and memory usage.\n",
    "\n",
    "3. **Chunks Less Than Workers ($c < w$)**:\n",
    "Here, the number of chunks is less than the available workers, resulting in idle workers and underutilization of resources.\n",
    "This scenario tests how Dask performs when some workers are not assigned tasks.\n",
    "The chunk-to-worker ratio ($r$) will be less than $1$, and the relative chunk size ($s$) will be larger, representing fewer but heavier tasks per worker.\n",
    "\n",
    "4. **Chunks Equal to Workers ($c = w$)**:\n",
    "In this balanced scenario, the number of chunks matches the number of workers, creating an ideal situation where every worker has exactly one task.\n",
    "The chunk-to-worker ratio ($r$) is $1$, and the relative chunk size ($s$) is moderate.\n",
    "This allows us to observe the effects of perfectly balanced workload distribution on execution time ($t_{\\text{exec}}$) and scheduling overhead ($t_{\\text{sched}}$).\n",
    "\n",
    "5. **Chunks Greater Than Workers ($c > w$)**:\n",
    "In this case, more chunks than workers are created, requiring workers to process multiple tasks.\n",
    "This configuration increases parallelism but may introduce higher task scheduling overhead ($t_{\\text{sched}}$) as more tasks are queued.\n",
    "The chunk-to-worker ratio ($r$) will be greater than $1$, while the relative chunk size ($s$) will be smaller, representing smaller, more numerous tasks per worker.\n",
    "\n",
    "By testing these configurations and observing the key metrics ($r$, $s$, $T$, $O_{\\text{sched}}$, and $M_{\\text{peak}}$), we aim to gain deeper insights into how chunk size impacts performance across various distributed environments.\n",
    "This will offer valuable guidelines for fine-tuning chunking strategies to make better use of system resources based on capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a19d27b-8693-4460-984b-1c93ef626731",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {\n",
    "    # 1 chunk for 1 worker (c = 1, r = 1, s = 1)\n",
    "    \"a\": (1, 1),\n",
    "\n",
    "    # 1 chunk for 3 workers (c = 1, r = 0.33, s = 1)\n",
    "    \"b\": (1, 3),\n",
    "\n",
    "    # 2 chunks for 5 workers (c ~ 1, r = 0.4, s = 0.125)\n",
    "    \"c\": (2, 5),\n",
    "\n",
    "    # 4 chunks for 5 workers (c ~ 1, r = 0.8, s = 0.015)\n",
    "    \"d\": (4, 5),\n",
    "\n",
    "    # 5 chunks for 10 workers (c < w, r = 0.5, s = 0.008)\n",
    "    #\"e\": (5, 10),  \n",
    "\n",
    "    # 10 chunks for 5 workers (c > w, r = 2, s = 0.001)\n",
    "    \"f\": (10, 5),\n",
    "\n",
    "    # 50 chunks for 5 workers (c > w, r = 10, s = 0.000008)\n",
    "    \"g\": (50, 5),\n",
    "\n",
    "    # 100 chunks for 10 workers (c > w, r = 10, s = 0.000001)\n",
    "    \"h\": (100, 10),\n",
    "\n",
    "    # 10 chunks for 10 workers (c = w, r = 1, s = 0.001)\n",
    "    \"i\": (10, 10),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858c2085-1d07-4a8f-8085-b980db40cef3",
   "metadata": {},
   "source": [
    "#### Experiment Execution\n",
    "\n",
    "In this section, we will test different configurations of chunks and workers to analyze their impact on distributed performance in Dask.\n",
    "The following procedure will be followed for each experiment iteration:\n",
    "\n",
    "1. Experiment Selection:\n",
    "We will select the next experiment configuration from the predefined set of experiments.\n",
    "Each configuration consists of a combination of the number of chunks ($c$) and the number of workers ($w$).\n",
    "\n",
    "2. Dask Cluster Setup:\n",
    "For each experiment, we will create a new Dask cluster with the specified number of workers ($w$).\n",
    "The cluster will manage task distribution and execution across the workers.\n",
    "\n",
    "3. Dask Array Chunking:\n",
    "We will create a Dask array representing the seismic cube and apply the specified chunking strategy based on the current experiment configuration.\n",
    "This array will be divided into $c$ chunks.\n",
    "\n",
    "4. Algorithm Execution:\n",
    "We will run the selected algorithms on the chunked Dask array:\n",
    "    - Envelope algorithm\n",
    "\t- GST3D (Generalized S-transform in 3D)\n",
    "\t- 3D Gaussian filtering.\n",
    "\n",
    "5. Metrics Collection:\n",
    "During the execution, we will collect the following metrics:\n",
    "\t- Execution Time ($T$): Total time taken for the computation.\n",
    "\t- Task Scheduling Overhead ($O_{sched}$): Time spent on scheduling tasks by Dask.\n",
    "\t- Memory Usage ($M_{peak}$): Peak memory usage during the execution.\n",
    "\n",
    "6. Repeat:\n",
    "We will iterate through the entire set of experiments, adjusting chunk sizes and worker counts, and repeating the process until all configurations have been tested.\n",
    "\n",
    "By the end of the experiment, we will have a dataset of performance metrics for each configuration.\n",
    "These results will help us analyze the relationship between chunk size, execution time, task scheduling overhead, and memory usage, providing insights into optimal chunking strategies in distributed systems like Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5095d124-fa91-4f5d-b0ed-dca04fc26dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_columns = [\n",
    "    'n_inlines',\n",
    "    'n_xlines',\n",
    "    'n_samples',\n",
    "    'experiment_name',\n",
    "    'c',\n",
    "    'w',\n",
    "    'r',\n",
    "    's',\n",
    "    'algorithm',\n",
    "    'T',\n",
    "    'O_sched',\n",
    "    'M_peak',\n",
    "]\n",
    "df_results = pd.DataFrame(columns=df_columns)\n",
    "enabled_algorithms = [apply_envelope, apply_gst3d, apply_gaussian_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abd23aa-a109-42a0-a7e3-11071e6c9b7c",
   "metadata": {},
   "source": [
    "To avoid Dask stacking unhandled memory and adding biases to the results, we need to scope each experiment iteration within a separate process that we can completely close before starting the next one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "651c6f2e-f995-48a4-b7f2-8f329e782871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scoped_experiment(pipe, algorithm, segy_path, c, w, experiment_name, memory_limit, num_inlines, num_xlines,\n",
    "                          num_samples):\n",
    "    import sys\n",
    "    import io\n",
    "    import time\n",
    "\n",
    "    from dask.distributed import Client, LocalCluster\n",
    "    from dask.utils import format_time, format_bytes\n",
    "\n",
    "    sys.path.append('../libs')\n",
    "\n",
    "    from utils import get_worker_peak_memory, OverheadPlugin\n",
    "\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = mystdout = io.StringIO()\n",
    "\n",
    "    with LocalCluster(\n",
    "            n_workers=w,\n",
    "            memory_limit=f'{memory_limit / w}GB',\n",
    "    ) as cluster:\n",
    "        with Client(cluster) as client:\n",
    "            overhead_plugin = OverheadPlugin()\n",
    "            cluster.scheduler.add_plugin(overhead_plugin)\n",
    "\n",
    "            start_time = time.perf_counter()\n",
    "            task = algorithm(seismic_data_path, chunks=(num_inlines / c, num_xlines / c, num_samples / c))\n",
    "            task.compute()\n",
    "            end_time = time.perf_counter()\n",
    "\n",
    "            execution_time = end_time - start_time\n",
    "            print(f\"Total Execution Time: {execution_time:.2f} seconds\")\n",
    "\n",
    "            peak_memory = client.run(get_worker_peak_memory)\n",
    "\n",
    "            avg_peak_memory = sum(peak_memory.values()) / len(peak_memory.values())\n",
    "            print(f\"Average Peak Memory Usage: {avg_peak_memory}\")\n",
    "\n",
    "            max_peak_memory = max(peak_memory.values())\n",
    "            print(f\"Max Peak Memory Usage: {max_peak_memory}\")\n",
    "            print(\"Peak Memory Usage per Worker:\")\n",
    "            for worker, mem_bytes in peak_memory.items():\n",
    "                print(f\"{worker}: {format_bytes(mem_bytes)}\")\n",
    "\n",
    "            total_overhead, max_overhead, avg_overhead = overhead_plugin.get_overhead_stats()\n",
    "            print(f\"\\nTotal Scheduling Overhead (sum of all task overheads): {format_time(total_overhead)}\")\n",
    "            print(f\"Maximum Scheduling Overhead per Task: {format_time(max_overhead)}\")\n",
    "            print(f\"Average Scheduling Overhead per Task: {format_time(avg_overhead)}\")\n",
    "\n",
    "            experiment_result = {\n",
    "                'n_inlines': num_inlines,\n",
    "                'n_xlines': num_xlines,\n",
    "                'n_samples': num_samples,\n",
    "                'experiment_name': experiment_name,\n",
    "                'c': c,\n",
    "                'w': w,\n",
    "                'r': c / w,\n",
    "                's': (num_inlines / c * num_xlines / c * num_samples / c) / (num_inlines * num_xlines * num_samples),\n",
    "                'algorithm': algorithm.__name__,\n",
    "                'T': execution_time,\n",
    "                'O_sched': max_overhead,\n",
    "                'M_peak': max_peak_memory,\n",
    "            }\n",
    "\n",
    "            sys.stdout = old_stdout\n",
    "\n",
    "            result = {\n",
    "                'logs': mystdout.getvalue(),\n",
    "                'experiment': experiment_result,\n",
    "            }\n",
    "\n",
    "            pipe.send(result)\n",
    "            pipe.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2d30b0-8ad6-498f-aa46-2d55c009bd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 20:32:08 - experiment-execution - INFO - Starting \u001B[43mexperiment \"A\"\u001B[0m for envelope_from_segy with 1 chunks and 1 workers\n",
      "2024-10-23 20:32:09 - envelope - INFO - Calculating envelope for ./outputs/001-20241023203203/data/300-300-300.segy\n",
      "2024-10-23 20:32:09 - envelope - INFO - Data shape: (300, 300, 300)\n",
      "2024-10-23 20:32:09 - envelope - INFO - Data chunks: ((300,), (300,), (300,))\n",
      "/home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 103.00 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "2024-10-23 20:32:10 - experiment-execution - INFO - Output from the subprocess logs:\n",
      "Total Execution Time: 0.89 seconds\n",
      "Average Peak Memory Usage: 899256320.0\n",
      "Max Peak Memory Usage: 899256320\n",
      "Peak Memory Usage per Worker:\n",
      "tcp://127.0.0.1:46571: 857.60 MiB\n",
      "\n",
      "Total Scheduling Overhead (sum of all task overheads): 31.48 ms\n",
      "Maximum Scheduling Overhead per Task: 31.38 ms\n",
      "Average Scheduling Overhead per Task: 15.74 ms\n",
      "\n",
      "/tmp/ipykernel_28054/3327904359.py:37: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_results = pd.concat([df_results, pd.DataFrame([experiment_result])], ignore_index=True)\n",
      "2024-10-23 20:32:10 - experiment-execution - INFO - Finished experiment \"A\" for envelope_from_segy with 1 chunks and 1 workers\n",
      "2024-10-23 20:32:10 - experiment-execution - INFO - Starting \u001B[43mexperiment \"A\"\u001B[0m for gradient_structure_tensor_from_segy with 1 chunks and 1 workers\n",
      "2024-10-23 20:32:11 - gst3d - INFO - Calculating GST3D for ./outputs/001-20241023203203/data/300-300-300.segy\n",
      "2024-10-23 20:32:11 - gst3d - INFO - Data shape: (300, 300, 300)\n",
      "2024-10-23 20:32:11 - gst3d - INFO - Data chunks: ((300,), (300,), (300,))\n",
      "/home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 103.04 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "2024-10-23 20:32:26 - experiment-execution - INFO - Output from the subprocess logs:\n",
      "Total Execution Time: 14.83 seconds\n",
      "Average Peak Memory Usage: 6983561216.0\n",
      "Max Peak Memory Usage: 6983561216\n",
      "Peak Memory Usage per Worker:\n",
      "tcp://127.0.0.1:45799: 6.50 GiB\n",
      "\n",
      "Total Scheduling Overhead (sum of all task overheads): 308.05 s\n",
      "Maximum Scheduling Overhead per Task: 883.06 ms\n",
      "Average Scheduling Overhead per Task: 647.16 ms\n",
      "\n",
      "2024-10-23 20:32:26 - experiment-execution - INFO - Finished experiment \"A\" for gradient_structure_tensor_from_segy with 1 chunks and 1 workers\n",
      "2024-10-23 20:32:26 - experiment-execution - INFO - Starting \u001B[43mexperiment \"A\"\u001B[0m for gaussian_filter_from_segy with 1 chunks and 1 workers\n",
      "2024-10-23 20:32:27 - gaussian_filter - INFO - Calculating Gaussian Filter for ./outputs/001-20241023203203/data/300-300-300.segy\n",
      "2024-10-23 20:32:27 - gaussian_filter - INFO - Data shape: (300, 300, 300)\n",
      "2024-10-23 20:32:27 - gaussian_filter - INFO - Data chunks: ((300,), (300,), (300,))\n",
      "/home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 103.00 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "2024-10-23 20:32:28 - experiment-execution - INFO - Output from the subprocess logs:\n",
      "Total Execution Time: 0.99 seconds\n",
      "Average Peak Memory Usage: 330276864.0\n",
      "Max Peak Memory Usage: 330276864\n",
      "Peak Memory Usage per Worker:\n",
      "tcp://127.0.0.1:34111: 314.98 MiB\n",
      "\n",
      "Total Scheduling Overhead (sum of all task overheads): 21.22 ms\n",
      "Maximum Scheduling Overhead per Task: 21.13 ms\n",
      "Average Scheduling Overhead per Task: 10.61 ms\n",
      "\n",
      "2024-10-23 20:32:28 - experiment-execution - INFO - Finished experiment \"A\" for gaussian_filter_from_segy with 1 chunks and 1 workers\n",
      "2024-10-23 20:32:28 - experiment-execution - INFO - Starting \u001B[43mexperiment \"B\"\u001B[0m for envelope_from_segy with 1 chunks and 3 workers\n",
      "2024-10-23 20:32:29 - envelope - INFO - Calculating envelope for ./outputs/001-20241023203203/data/300-300-300.segy\n",
      "2024-10-23 20:32:29 - envelope - INFO - Data shape: (300, 300, 300)\n",
      "2024-10-23 20:32:29 - envelope - INFO - Data chunks: ((300,), (300,), (300,))\n",
      "/home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 103.00 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "2024-10-23 20:32:30 - experiment-execution - INFO - Output from the subprocess logs:\n",
      "Total Execution Time: 0.86 seconds\n",
      "Average Peak Memory Usage: 496741034.6666667\n",
      "Max Peak Memory Usage: 900907008\n",
      "Peak Memory Usage per Worker:\n",
      "tcp://127.0.0.1:32977: 859.17 MiB\n",
      "tcp://127.0.0.1:41309: 281.01 MiB\n",
      "tcp://127.0.0.1:45197: 281.01 MiB\n",
      "\n",
      "Total Scheduling Overhead (sum of all task overheads): 22.85 ms\n",
      "Maximum Scheduling Overhead per Task: 22.75 ms\n",
      "Average Scheduling Overhead per Task: 11.43 ms\n",
      "\n",
      "2024-10-23 20:32:30 - experiment-execution - INFO - Finished experiment \"B\" for envelope_from_segy with 1 chunks and 3 workers\n",
      "2024-10-23 20:32:30 - experiment-execution - INFO - Starting \u001B[43mexperiment \"B\"\u001B[0m for gradient_structure_tensor_from_segy with 1 chunks and 3 workers\n",
      "2024-10-23 20:32:31 - gst3d - INFO - Calculating GST3D for ./outputs/001-20241023203203/data/300-300-300.segy\n",
      "2024-10-23 20:32:31 - gst3d - INFO - Data shape: (300, 300, 300)\n",
      "2024-10-23 20:32:31 - gst3d - INFO - Data chunks: ((300,), (300,), (300,))\n",
      "/home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 103.04 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "2024-10-23 20:32:39,521 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.29 GiB -- Worker memory limit: 7.45 GiB\n",
      "2024-10-23 20:32:42,094 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 5.97 GiB -- Worker memory limit: 7.45 GiB\n",
      "2024-10-23 20:32:44,055 - distributed.worker.memory - WARNING - Worker is at 64% memory usage. Resuming worker. Process memory: 4.78 GiB -- Worker memory limit: 7.45 GiB\n",
      "2024-10-23 20:32:46 - experiment-execution - INFO - Output from the subprocess logs:\n",
      "Total Execution Time: 14.89 seconds\n",
      "Average Peak Memory Usage: 2522449237.3333335\n",
      "Max Peak Memory Usage: 6977904640\n",
      "Peak Memory Usage per Worker:\n",
      "tcp://127.0.0.1:35813: 281.00 MiB\n",
      "tcp://127.0.0.1:36653: 6.50 GiB\n",
      "tcp://127.0.0.1:41357: 281.13 MiB\n",
      "\n",
      "Total Scheduling Overhead (sum of all task overheads): 315.40 s\n",
      "Maximum Scheduling Overhead per Task: 933.27 ms\n",
      "Average Scheduling Overhead per Task: 662.61 ms\n",
      "\n",
      "2024-10-23 20:32:46 - experiment-execution - INFO - Finished experiment \"B\" for gradient_structure_tensor_from_segy with 1 chunks and 3 workers\n",
      "2024-10-23 20:32:46 - experiment-execution - INFO - Starting \u001B[43mexperiment \"B\"\u001B[0m for gaussian_filter_from_segy with 1 chunks and 3 workers\n",
      "2024-10-23 20:32:48 - gaussian_filter - INFO - Calculating Gaussian Filter for ./outputs/001-20241023203203/data/300-300-300.segy\n",
      "2024-10-23 20:32:48 - gaussian_filter - INFO - Data shape: (300, 300, 300)\n",
      "2024-10-23 20:32:48 - gaussian_filter - INFO - Data chunks: ((300,), (300,), (300,))\n",
      "/home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 103.00 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "2024-10-23 20:32:49 - experiment-execution - INFO - Output from the subprocess logs:\n",
      "Total Execution Time: 1.04 seconds\n",
      "Average Peak Memory Usage: 306552832.0\n",
      "Max Peak Memory Usage: 330285056\n",
      "Peak Memory Usage per Worker:\n",
      "tcp://127.0.0.1:32801: 314.98 MiB\n",
      "tcp://127.0.0.1:34407: 281.04 MiB\n",
      "tcp://127.0.0.1:45829: 281.04 MiB\n",
      "\n",
      "Total Scheduling Overhead (sum of all task overheads): 21.23 ms\n",
      "Maximum Scheduling Overhead per Task: 21.14 ms\n",
      "Average Scheduling Overhead per Task: 10.61 ms\n",
      "\n",
      "2024-10-23 20:32:49 - experiment-execution - INFO - Finished experiment \"B\" for gaussian_filter_from_segy with 1 chunks and 3 workers\n",
      "2024-10-23 20:32:49 - experiment-execution - INFO - Starting \u001B[43mexperiment \"C\"\u001B[0m for envelope_from_segy with 2 chunks and 5 workers\n",
      "2024-10-23 20:32:50 - envelope - INFO - Calculating envelope for ./outputs/001-20241023203203/data/300-300-300.segy\n",
      "2024-10-23 20:32:50 - envelope - INFO - Data shape: (300, 300, 300)\n",
      "2024-10-23 20:32:50 - envelope - INFO - Data chunks: ((150, 150), (150, 150), (150, 150))\n",
      "/home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 103.00 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "2024-10-23 20:32:51 - experiment-execution - INFO - Output from the subprocess logs:\n",
      "Total Execution Time: 0.94 seconds\n",
      "Average Peak Memory Usage: 316256256.0\n",
      "Max Peak Memory Usage: 336445440\n",
      "Peak Memory Usage per Worker:\n",
      "tcp://127.0.0.1:33337: 313.29 MiB\n",
      "tcp://127.0.0.1:35247: 320.86 MiB\n",
      "tcp://127.0.0.1:38641: 311.47 MiB\n",
      "tcp://127.0.0.1:41117: 281.14 MiB\n",
      "tcp://127.0.0.1:41397: 281.27 MiB\n",
      "\n",
      "Total Scheduling Overhead (sum of all task overheads): 403.86 ms\n",
      "Maximum Scheduling Overhead per Task: 62.96 ms\n",
      "Average Scheduling Overhead per Task: 25.24 ms\n",
      "\n",
      "2024-10-23 20:32:51 - experiment-execution - INFO - Finished experiment \"C\" for envelope_from_segy with 2 chunks and 5 workers\n",
      "2024-10-23 20:32:51 - experiment-execution - INFO - Starting \u001B[43mexperiment \"C\"\u001B[0m for gradient_structure_tensor_from_segy with 2 chunks and 5 workers\n",
      "2024-10-23 20:32:52 - gst3d - INFO - Calculating GST3D for ./outputs/001-20241023203203/data/300-300-300.segy\n",
      "2024-10-23 20:32:52 - gst3d - INFO - Data shape: (300, 300, 300)\n",
      "2024-10-23 20:32:52 - gst3d - INFO - Data chunks: ((150, 150), (150, 150), (150, 150))\n",
      "/home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 103.20 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "2024-10-23 20:32:58 - experiment-execution - INFO - Output from the subprocess logs:\n",
      "Total Execution Time: 5.71 seconds\n",
      "Average Peak Memory Usage: 1507959603.2\n",
      "Max Peak Memory Usage: 1841500160\n",
      "Peak Memory Usage per Worker:\n",
      "tcp://127.0.0.1:34099: 0.95 GiB\n",
      "tcp://127.0.0.1:34109: 0.96 GiB\n",
      "tcp://127.0.0.1:34681: 1.70 GiB\n",
      "tcp://127.0.0.1:43479: 1.71 GiB\n",
      "tcp://127.0.0.1:44603: 1.72 GiB\n",
      "\n",
      "Total Scheduling Overhead (sum of all task overheads): 30m 56s\n",
      "Maximum Scheduling Overhead per Task: 1.91 s\n",
      "Average Scheduling Overhead per Task: 739.18 ms\n",
      "\n",
      "2024-10-23 20:32:58 - experiment-execution - INFO - Finished experiment \"C\" for gradient_structure_tensor_from_segy with 2 chunks and 5 workers\n",
      "2024-10-23 20:32:58 - experiment-execution - INFO - Starting \u001B[43mexperiment \"C\"\u001B[0m for gaussian_filter_from_segy with 2 chunks and 5 workers\n",
      "2024-10-23 20:33:00 - gaussian_filter - INFO - Calculating Gaussian Filter for ./outputs/001-20241023203203/data/300-300-300.segy\n",
      "2024-10-23 20:33:00 - gaussian_filter - INFO - Data shape: (300, 300, 300)\n",
      "2024-10-23 20:33:00 - gaussian_filter - INFO - Data chunks: ((150, 150), (150, 150), (150, 150))\n",
      "/home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 103.00 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "2024-10-23 20:33:01 - experiment-execution - INFO - Output from the subprocess logs:\n",
      "Total Execution Time: 0.79 seconds\n",
      "Average Peak Memory Usage: 294863667.2\n",
      "Max Peak Memory Usage: 294944768\n",
      "Peak Memory Usage per Worker:\n",
      "tcp://127.0.0.1:35413: 281.15 MiB\n",
      "tcp://127.0.0.1:35561: 281.28 MiB\n",
      "tcp://127.0.0.1:36257: 281.15 MiB\n",
      "tcp://127.0.0.1:36373: 281.15 MiB\n",
      "tcp://127.0.0.1:37829: 281.28 MiB\n",
      "\n",
      "Total Scheduling Overhead (sum of all task overheads): 632.07 ms\n",
      "Maximum Scheduling Overhead per Task: 161.65 ms\n",
      "Average Scheduling Overhead per Task: 39.50 ms\n",
      "\n",
      "2024-10-23 20:33:01 - experiment-execution - INFO - Finished experiment \"C\" for gaussian_filter_from_segy with 2 chunks and 5 workers\n",
      "2024-10-23 20:33:01 - experiment-execution - INFO - Starting \u001B[43mexperiment \"D\"\u001B[0m for envelope_from_segy with 4 chunks and 5 workers\n",
      "2024-10-23 20:33:02 - envelope - INFO - Calculating envelope for ./outputs/001-20241023203203/data/300-300-300.segy\n",
      "2024-10-23 20:33:02 - envelope - INFO - Data shape: (300, 300, 300)\n",
      "2024-10-23 20:33:02 - envelope - INFO - Data chunks: ((75, 75, 75, 75), (75, 75, 75, 75), (75, 75, 75, 75))\n",
      "/home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 103.00 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "2024-10-23 20:33:03 - experiment-execution - INFO - Output from the subprocess logs:\n",
      "Total Execution Time: 1.07 seconds\n",
      "Average Peak Memory Usage: 294857113.6\n",
      "Max Peak Memory Usage: 294940672\n",
      "Peak Memory Usage per Worker:\n",
      "tcp://127.0.0.1:33249: 281.14 MiB\n",
      "tcp://127.0.0.1:37825: 281.14 MiB\n",
      "tcp://127.0.0.1:41207: 281.28 MiB\n",
      "tcp://127.0.0.1:46203: 281.14 MiB\n",
      "tcp://127.0.0.1:46495: 281.28 MiB\n",
      "\n",
      "Total Scheduling Overhead (sum of all task overheads): 32.85 s\n",
      "Maximum Scheduling Overhead per Task: 461.83 ms\n",
      "Average Scheduling Overhead per Task: 256.66 ms\n",
      "\n",
      "2024-10-23 20:33:03 - experiment-execution - INFO - Finished experiment \"D\" for envelope_from_segy with 4 chunks and 5 workers\n",
      "2024-10-23 20:33:03 - experiment-execution - INFO - Starting \u001B[43mexperiment \"D\"\u001B[0m for gradient_structure_tensor_from_segy with 4 chunks and 5 workers\n",
      "2024-10-23 20:33:04 - gst3d - INFO - Calculating GST3D for ./outputs/001-20241023203203/data/300-300-300.segy\n",
      "2024-10-23 20:33:04 - gst3d - INFO - Data shape: (300, 300, 300)\n",
      "2024-10-23 20:33:04 - gst3d - INFO - Data chunks: ((75, 75, 75, 75), (75, 75, 75, 75), (75, 75, 75, 75))\n",
      "/home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 104.29 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "2024-10-23 20:33:15 - experiment-execution - INFO - Output from the subprocess logs:\n",
      "Total Execution Time: 10.78 seconds\n",
      "Average Peak Memory Usage: 652874547.2\n",
      "Max Peak Memory Usage: 679907328\n",
      "Peak Memory Usage per Worker:\n",
      "tcp://127.0.0.1:36233: 615.58 MiB\n",
      "tcp://127.0.0.1:43123: 591.98 MiB\n",
      "tcp://127.0.0.1:43781: 635.19 MiB\n",
      "tcp://127.0.0.1:45613: 648.41 MiB\n",
      "tcp://127.0.0.1:45833: 621.99 MiB\n",
      "\n",
      "Total Scheduling Overhead (sum of all task overheads): 10hr 35m\n",
      "Maximum Scheduling Overhead per Task: 6.76 s\n",
      "Average Scheduling Overhead per Task: 2.49 s\n",
      "\n",
      "2024-10-23 20:33:15 - experiment-execution - INFO - Finished experiment \"D\" for gradient_structure_tensor_from_segy with 4 chunks and 5 workers\n",
      "2024-10-23 20:33:15 - experiment-execution - INFO - Starting \u001B[43mexperiment \"D\"\u001B[0m for gaussian_filter_from_segy with 4 chunks and 5 workers\n",
      "2024-10-23 20:33:17 - gaussian_filter - INFO - Calculating Gaussian Filter for ./outputs/001-20241023203203/data/300-300-300.segy\n",
      "2024-10-23 20:33:17 - gaussian_filter - INFO - Data shape: (300, 300, 300)\n",
      "2024-10-23 20:33:17 - gaussian_filter - INFO - Data chunks: ((75, 75, 75, 75), (75, 75, 75, 75), (75, 75, 75, 75))\n",
      "/home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 103.00 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "2024-10-23 20:33:18 - experiment-execution - INFO - Output from the subprocess logs:\n",
      "Total Execution Time: 0.82 seconds\n",
      "Average Peak Memory Usage: 294893158.4\n",
      "Max Peak Memory Usage: 294948864\n",
      "Peak Memory Usage per Worker:\n",
      "tcp://127.0.0.1:34303: 281.29 MiB\n",
      "tcp://127.0.0.1:35603: 281.29 MiB\n",
      "tcp://127.0.0.1:36487: 281.29 MiB\n",
      "tcp://127.0.0.1:36749: 281.15 MiB\n",
      "tcp://127.0.0.1:40879: 281.15 MiB\n",
      "\n",
      "Total Scheduling Overhead (sum of all task overheads): 15.76 s\n",
      "Maximum Scheduling Overhead per Task: 225.87 ms\n",
      "Average Scheduling Overhead per Task: 123.13 ms\n",
      "\n",
      "2024-10-23 20:33:18 - experiment-execution - INFO - Finished experiment \"D\" for gaussian_filter_from_segy with 4 chunks and 5 workers\n",
      "2024-10-23 20:33:18 - experiment-execution - INFO - Starting \u001B[43mexperiment \"F\"\u001B[0m for envelope_from_segy with 10 chunks and 5 workers\n",
      "2024-10-23 20:33:19 - envelope - INFO - Calculating envelope for ./outputs/001-20241023203203/data/300-300-300.segy\n",
      "2024-10-23 20:33:19 - envelope - INFO - Data shape: (300, 300, 300)\n",
      "2024-10-23 20:33:19 - envelope - INFO - Data chunks: ((30, 30, 30, 30, 30, 30, 30, 30, 30, 30), (30, 30, 30, 30, 30, 30, 30, 30, 30, 30), (30, 30, 30, 30, 30, 30, 30, 30, 30, 30))\n",
      "/home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 103.09 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "2024-10-23 20:33:22 - experiment-execution - INFO - Output from the subprocess logs:\n",
      "Total Execution Time: 3.02 seconds\n",
      "Average Peak Memory Usage: 294902169.6\n",
      "Max Peak Memory Usage: 294961152\n",
      "Peak Memory Usage per Worker:\n",
      "tcp://127.0.0.1:36147: 281.16 MiB\n",
      "tcp://127.0.0.1:37545: 281.30 MiB\n",
      "tcp://127.0.0.1:38461: 281.30 MiB\n",
      "tcp://127.0.0.1:41083: 281.16 MiB\n",
      "tcp://127.0.0.1:41269: 281.30 MiB\n",
      "\n",
      "Total Scheduling Overhead (sum of all task overheads): 37m 12s\n",
      "Maximum Scheduling Overhead per Task: 1.99 s\n",
      "Average Scheduling Overhead per Task: 1.12 s\n",
      "\n",
      "2024-10-23 20:33:22 - experiment-execution - INFO - Finished experiment \"F\" for envelope_from_segy with 10 chunks and 5 workers\n",
      "2024-10-23 20:33:22 - experiment-execution - INFO - Starting \u001B[43mexperiment \"F\"\u001B[0m for gradient_structure_tensor_from_segy with 10 chunks and 5 workers\n",
      "2024-10-23 20:33:23 - gst3d - INFO - Calculating GST3D for ./outputs/001-20241023203203/data/300-300-300.segy\n",
      "2024-10-23 20:33:23 - gst3d - INFO - Data shape: (300, 300, 300)\n",
      "2024-10-23 20:33:23 - gst3d - INFO - Data chunks: ((30, 30, 30, 30, 30, 30, 30, 30, 30, 30), (30, 30, 30, 30, 30, 30, 30, 30, 30, 30), (30, 30, 30, 30, 30, 30, 30, 30, 30, 30))\n",
      "/home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 121.78 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "2024-10-23 20:35:16 - experiment-execution - INFO - Output from the subprocess logs:\n",
      "Total Execution Time: 111.87 seconds\n",
      "Average Peak Memory Usage: 471291494.4\n",
      "Max Peak Memory Usage: 478527488\n",
      "Peak Memory Usage per Worker:\n",
      "tcp://127.0.0.1:34101: 449.70 MiB\n",
      "tcp://127.0.0.1:38937: 456.36 MiB\n",
      "tcp://127.0.0.1:42101: 441.43 MiB\n",
      "tcp://127.0.0.1:44563: 455.29 MiB\n",
      "tcp://127.0.0.1:44779: 444.51 MiB\n",
      "\n",
      "Total Scheduling Overhead (sum of all task overheads): 72d 7hr\n",
      "Maximum Scheduling Overhead per Task: 68.11 s\n",
      "Average Scheduling Overhead per Task: 29.49 s\n",
      "\n",
      "2024-10-23 20:35:16 - experiment-execution - INFO - Finished experiment \"F\" for gradient_structure_tensor_from_segy with 10 chunks and 5 workers\n",
      "2024-10-23 20:35:16 - experiment-execution - INFO - Starting \u001B[43mexperiment \"F\"\u001B[0m for gaussian_filter_from_segy with 10 chunks and 5 workers\n",
      "2024-10-23 20:35:17 - gaussian_filter - INFO - Calculating Gaussian Filter for ./outputs/001-20241023203203/data/300-300-300.segy\n",
      "2024-10-23 20:35:17 - gaussian_filter - INFO - Data shape: (300, 300, 300)\n",
      "2024-10-23 20:35:17 - gaussian_filter - INFO - Data chunks: ((30, 30, 30, 30, 30, 30, 30, 30, 30, 30), (30, 30, 30, 30, 30, 30, 30, 30, 30, 30), (30, 30, 30, 30, 30, 30, 30, 30, 30, 30))\n",
      "/home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 103.09 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "2024-10-23 20:35:19 - experiment-execution - INFO - Output from the subprocess logs:\n",
      "Total Execution Time: 1.85 seconds\n",
      "Average Peak Memory Usage: 294748160.0\n",
      "Max Peak Memory Usage: 294805504\n",
      "Peak Memory Usage per Worker:\n",
      "tcp://127.0.0.1:33061: 281.15 MiB\n",
      "tcp://127.0.0.1:35239: 281.15 MiB\n",
      "tcp://127.0.0.1:44127: 281.01 MiB\n",
      "tcp://127.0.0.1:45557: 281.01 MiB\n",
      "tcp://127.0.0.1:46819: 281.15 MiB\n",
      "\n",
      "Total Scheduling Overhead (sum of all task overheads): 17m 39s\n",
      "Maximum Scheduling Overhead per Task: 933.14 ms\n",
      "Average Scheduling Overhead per Task: 529.57 ms\n",
      "\n",
      "2024-10-23 20:35:19 - experiment-execution - INFO - Finished experiment \"F\" for gaussian_filter_from_segy with 10 chunks and 5 workers\n",
      "2024-10-23 20:35:19 - experiment-execution - INFO - Starting \u001B[43mexperiment \"G\"\u001B[0m for envelope_from_segy with 50 chunks and 5 workers\n",
      "2024-10-23 20:35:21 - envelope - INFO - Calculating envelope for ./outputs/001-20241023203203/data/300-300-300.segy\n",
      "2024-10-23 20:35:21 - envelope - INFO - Data shape: (300, 300, 300)\n",
      "2024-10-23 20:35:21 - envelope - INFO - Data chunks: ((6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6), (6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6), (6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6))\n",
      "/home/delucca/.pyenv/versions/3.10.14/envs/dask-auto-chunking/lib/python3.10/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 113.27 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "2024-10-23 20:39:26 - experiment-execution - INFO - Output from the subprocess logs:\n",
      "Total Execution Time: 239.89 seconds\n",
      "Average Peak Memory Usage: 505139200.0\n",
      "Max Peak Memory Usage: 506650624\n",
      "Peak Memory Usage per Worker:\n",
      "tcp://127.0.0.1:37715: 481.49 MiB\n",
      "tcp://127.0.0.1:38237: 479.89 MiB\n",
      "tcp://127.0.0.1:40245: 481.36 MiB\n",
      "tcp://127.0.0.1:45399: 482.77 MiB\n",
      "tcp://127.0.0.1:46409: 483.18 MiB\n",
      "\n",
      "Total Scheduling Overhead (sum of all task overheads): 273d 22hr\n",
      "Maximum Scheduling Overhead per Task: 184.17 s\n",
      "Average Scheduling Overhead per Task: 94.67 s\n",
      "\n",
      "2024-10-23 20:39:26 - experiment-execution - INFO - Finished experiment \"G\" for envelope_from_segy with 50 chunks and 5 workers\n",
      "2024-10-23 20:39:26 - experiment-execution - INFO - Starting \u001B[43mexperiment \"G\"\u001B[0m for gradient_structure_tensor_from_segy with 50 chunks and 5 workers\n",
      "2024-10-23 20:39:28 - gst3d - INFO - Calculating GST3D for ./outputs/001-20241023203203/data/300-300-300.segy\n",
      "2024-10-23 20:39:28 - gst3d - INFO - Data shape: (300, 300, 300)\n",
      "2024-10-23 20:39:28 - gst3d - INFO - Data chunks: ((6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6), (6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6), (6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6))\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "from loggers import get_named_logger\n",
    "\n",
    "MEMORY_LIMIT = 24  # In GB\n",
    "RESULT_FILE = f'{OUTPUT_DIR}/results.pkl'\n",
    "\n",
    "logger = get_named_logger('experiment-execution')\n",
    "\n",
    "for experiment_name, (num_chunks, num_workers) in experiments.items():\n",
    "    for algorithm in enabled_algorithms:\n",
    "        logger.info(\n",
    "            f'Starting \\033[43mexperiment \"{experiment_name.upper()}\"\\033[0m for {algorithm.__name__} with {num_chunks} chunks and {num_workers} workers')\n",
    "\n",
    "        parent_conn, child_conn = multiprocessing.Pipe()\n",
    "        p = multiprocessing.Process(\n",
    "            target=run_scoped_experiment,\n",
    "            args=(\n",
    "                child_conn,\n",
    "                algorithm,\n",
    "                seismic_data_path,\n",
    "                num_chunks,\n",
    "                num_workers,\n",
    "                experiment_name,\n",
    "                MEMORY_LIMIT,\n",
    "                NUM_INLINES,\n",
    "                NUM_XLINES,\n",
    "                NUM_SAMPLES,\n",
    "            )\n",
    "        )\n",
    "        p.start()\n",
    "        p.join()\n",
    "        result = parent_conn.recv()\n",
    "        experiment_result = result['experiment']\n",
    "\n",
    "        logger.info(\"Output from the subprocess logs:\\n\" + result['logs'])\n",
    "\n",
    "        df_results = pd.concat([df_results, pd.DataFrame([experiment_result])], ignore_index=True)\n",
    "        df_results.to_pickle(RESULT_FILE)\n",
    "\n",
    "        logger.info(\n",
    "            f'Finished experiment \"{experiment_name.upper()}\" for {algorithm.__name__} with {num_chunks} chunks and {num_workers} workers')\n",
    "\n",
    "with pd.option_context('display.max_columns', None, 'display.max_colwidth', None):\n",
    "    display(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1cbaf0e-0520-4060-b281-eb3f7cf44eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_inlines</th>\n",
       "      <th>n_xlines</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>c</th>\n",
       "      <th>w</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>T</th>\n",
       "      <th>O_sched</th>\n",
       "      <th>M_peak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>envelope_from_segy</td>\n",
       "      <td>0.885155</td>\n",
       "      <td>0.031385</td>\n",
       "      <td>899256320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>gradient_structure_tensor_from_segy</td>\n",
       "      <td>14.826689</td>\n",
       "      <td>0.883056</td>\n",
       "      <td>6983561216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>gaussian_filter_from_segy</td>\n",
       "      <td>0.985606</td>\n",
       "      <td>0.021127</td>\n",
       "      <td>330276864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>envelope_from_segy</td>\n",
       "      <td>0.864921</td>\n",
       "      <td>0.022748</td>\n",
       "      <td>900907008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>gradient_structure_tensor_from_segy</td>\n",
       "      <td>14.892932</td>\n",
       "      <td>0.933269</td>\n",
       "      <td>6977904640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>gaussian_filter_from_segy</td>\n",
       "      <td>1.039439</td>\n",
       "      <td>0.021136</td>\n",
       "      <td>330285056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>envelope_from_segy</td>\n",
       "      <td>0.935808</td>\n",
       "      <td>0.062960</td>\n",
       "      <td>336445440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>gradient_structure_tensor_from_segy</td>\n",
       "      <td>5.710416</td>\n",
       "      <td>1.909975</td>\n",
       "      <td>1841500160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>gaussian_filter_from_segy</td>\n",
       "      <td>0.794163</td>\n",
       "      <td>0.161645</td>\n",
       "      <td>294944768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>d</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>envelope_from_segy</td>\n",
       "      <td>1.065954</td>\n",
       "      <td>0.461830</td>\n",
       "      <td>294940672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>d</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>gradient_structure_tensor_from_segy</td>\n",
       "      <td>10.775418</td>\n",
       "      <td>6.757581</td>\n",
       "      <td>679907328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>d</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>gaussian_filter_from_segy</td>\n",
       "      <td>0.819613</td>\n",
       "      <td>0.225874</td>\n",
       "      <td>294948864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>f</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>envelope_from_segy</td>\n",
       "      <td>3.021311</td>\n",
       "      <td>1.989943</td>\n",
       "      <td>294961152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>f</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>gradient_structure_tensor_from_segy</td>\n",
       "      <td>111.869280</td>\n",
       "      <td>68.109090</td>\n",
       "      <td>478527488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>f</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>gaussian_filter_from_segy</td>\n",
       "      <td>1.845110</td>\n",
       "      <td>0.933136</td>\n",
       "      <td>294805504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>g</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>envelope_from_segy</td>\n",
       "      <td>239.891946</td>\n",
       "      <td>184.174577</td>\n",
       "      <td>506650624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_inlines n_xlines n_samples experiment_name   c  w          r         s  \\\n",
       "0        300      300       300               a   1  1   1.000000  1.000000   \n",
       "1        300      300       300               a   1  1   1.000000  1.000000   \n",
       "2        300      300       300               a   1  1   1.000000  1.000000   \n",
       "3        300      300       300               b   1  3   0.333333  1.000000   \n",
       "4        300      300       300               b   1  3   0.333333  1.000000   \n",
       "5        300      300       300               b   1  3   0.333333  1.000000   \n",
       "6        300      300       300               c   2  5   0.400000  0.125000   \n",
       "7        300      300       300               c   2  5   0.400000  0.125000   \n",
       "8        300      300       300               c   2  5   0.400000  0.125000   \n",
       "9        300      300       300               d   4  5   0.800000  0.015625   \n",
       "10       300      300       300               d   4  5   0.800000  0.015625   \n",
       "11       300      300       300               d   4  5   0.800000  0.015625   \n",
       "12       300      300       300               f  10  5   2.000000  0.001000   \n",
       "13       300      300       300               f  10  5   2.000000  0.001000   \n",
       "14       300      300       300               f  10  5   2.000000  0.001000   \n",
       "15       300      300       300               g  50  5  10.000000  0.000008   \n",
       "\n",
       "                              algorithm           T     O_sched      M_peak  \n",
       "0                    envelope_from_segy    0.885155    0.031385   899256320  \n",
       "1   gradient_structure_tensor_from_segy   14.826689    0.883056  6983561216  \n",
       "2             gaussian_filter_from_segy    0.985606    0.021127   330276864  \n",
       "3                    envelope_from_segy    0.864921    0.022748   900907008  \n",
       "4   gradient_structure_tensor_from_segy   14.892932    0.933269  6977904640  \n",
       "5             gaussian_filter_from_segy    1.039439    0.021136   330285056  \n",
       "6                    envelope_from_segy    0.935808    0.062960   336445440  \n",
       "7   gradient_structure_tensor_from_segy    5.710416    1.909975  1841500160  \n",
       "8             gaussian_filter_from_segy    0.794163    0.161645   294944768  \n",
       "9                    envelope_from_segy    1.065954    0.461830   294940672  \n",
       "10  gradient_structure_tensor_from_segy   10.775418    6.757581   679907328  \n",
       "11            gaussian_filter_from_segy    0.819613    0.225874   294948864  \n",
       "12                   envelope_from_segy    3.021311    1.989943   294961152  \n",
       "13  gradient_structure_tensor_from_segy  111.869280   68.109090   478527488  \n",
       "14            gaussian_filter_from_segy    1.845110    0.933136   294805504  \n",
       "15                   envelope_from_segy  239.891946  184.174577   506650624  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle('./outputs/001-20241023203203/results.pkl')\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
